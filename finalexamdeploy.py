# -*- coding: utf-8 -*-
"""FinalExamDeploy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wydcuv0btDzfsQMzWb88RUk4K77SXUKk
"""

# Install all required libraries
#pip install streamlit pandas scikit-learn -q
#npm install localtunnel

# Commented out IPython magic to ensure Python compatibility.
# %%writefile hmeqapp.py
# 
# # -*- coding: utf-8 -*-
# import streamlit as st
# import pickle
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler # Required to unpickle the scaler
# 
# # Load the trained model, scaler, feature columns, imputation medians, and categorical options
# with open("/content/drive/MyDrive/BUS 458 Final/final_exam_model.pkl", "rb") as file:
#     model = pickle.load(file)
# 
# with open("scaler.pkl", "rb") as file:
#     scaler = pickle.load(file)
# 
# with open("feature_columns.pkl", "rb") as file:
#     feature_columns = pickle.load(file)
# 
# with open("imputation_medians.pkl", "rb") as file:
#     imputation_medians = pickle.load(file)
# 
# with open("categorical_options.pkl", "rb") as file:
#     categorical_options = pickle.load(file)
# 
# # Title for the app
# st.markdown(
#     "<h1 style='text-align: center; background-color: #f0f2f6; padding: 10px; color: #31333F;'><b>Loan Approval Prediction</b></h1>",
#     unsafe_allow_html=True
# )
# 
# st.header("Enter Applicant's Details")
# 
# # Input fields for numerical values
# st.subheader("Numerical Features")
# applications = st.number_input("Applications (APPLICATIONS)", min_value=1, max_value=10, value=1)
# granted_loan_amount = st.slider("Granted Loan Amount", min_value=5000, max_value=2000000, value=50000, step=1000)
# requested_loan_amount = st.slider("Requested Loan Amount", min_value=5000, max_value=2500000, value=60000, step=1000)
# fico_score = st.slider("FICO Score", min_value=300, max_value=850, value=650, step=1)
# monthly_gross_income = st.slider("Monthly Gross Income", min_value=0, max_value=20000, value=5000, step=100)
# monthly_housing_payment = st.slider("Monthly Housing Payment", min_value=300, max_value=50000, value=1500, step=100)
# 
# # Input fields for categorical values
# st.subheader("Categorical Features")
# reason = st.selectbox("Reason for Loan", categorical_options['Reason'])
# employment_status = st.selectbox("Employment Status", categorical_options['Employment_Status'])
# lender = st.selectbox("Lender", categorical_options['Lender'])
# fico_score_group = st.selectbox("Fico Score Group", categorical_options['Fico_Score_group'])
# employment_sector = st.selectbox("Employment Sector", categorical_options['Employment_Sector'])
# ever_bankrupt_or_foreclose = st.selectbox("Ever Bankrupt or Foreclose", [0, 1], format_func=lambda x: "Yes" if x == 1 else "No")
# 
# # Create a button to make predictions
# if st.button("Predict Loan Approval"):
#     # Create a DataFrame from current inputs (before preprocessing)
#     input_df = pd.DataFrame({
#         'applications': [applications],
#         'Granted_Loan_Amount': [granted_loan_amount],
#         'Requested_Loan_Amount': [requested_loan_amount],
#         'FICO_score': [fico_score],
#         'Monthly_Gross_Income': [monthly_gross_income],
#         'Monthly_Housing_Payment': [monthly_housing_payment],
#         'Reason': [reason],
#         'Employment_Status': [employment_status],
#         'Lender': [lender],
#         'Fico_Score_group': [fico_score_group],
#         'Employment_Sector': [employment_sector],
#         'Ever_Bankrupt_or_Foreclose': [ever_bankrupt_or_foreclose]
#     })
# 
#     # --- Preprocessing identical to training data ---
# 
#     # 1. Impute missing numerical values (if any in original input, though sliders prevent this here)
#     # We use saved medians, though for Streamlit inputs, this step might be redundant if all inputs are provided
#     input_df['FICO_score'] = input_df['FICO_score'].fillna(imputation_medians['FICO_score'])
#     input_df['Monthly_Gross_Income'] = input_df['Monthly_Gross_Income'].fillna(imputation_medians['Monthly_Gross_Income'])
# 
#     # 2. Feature Engineering: Create ratio features
#     input_df['granted_requested_ratio'] = input_df['Granted_Loan_Amount'] / input_df['Requested_Loan_Amount']
#     input_df['housing_to_income_ratio'] = input_df['Monthly_Housing_Payment'] / input_df['Monthly_Gross_Income']
# 
#     # Handle potential inf/-inf from division by zero, fillna(0) for engineered features
#     input_df.replace([np.inf, -np.inf], np.nan, inplace=True)
#     input_df['granted_requested_ratio'] = input_df['granted_requested_ratio'].fillna(0)
#     input_df['housing_to_income_ratio'] = input_df['housing_to_income_ratio'].fillna(0)
# 
#     # Separate numerical and categorical for consistent processing
#     numerical_cols_for_scaling = [
#         'applications', 'Granted_Loan_Amount', 'Requested_Loan_Amount',
#         'FICO_score', 'Monthly_Gross_Income', 'Monthly_Housing_Payment',
#         'granted_requested_ratio', 'housing_to_income_ratio'
#     ]
#     categorical_cols_for_ohe = [
#         'Reason', 'Employment_Status', 'Lender', 'Fico_Score_group',
#         'Employment_Sector', 'Ever_Bankrupt_or_Foreclose'
#     ]
# 
#     input_numerical = input_df[numerical_cols_for_scaling]
#     input_categorical = input_df[categorical_cols_for_ohe]
# 
#     # 3. Scale numerical features
#     input_numerical_scaled = scaler.transform(input_numerical)
#     input_numerical_scaled_df = pd.DataFrame(
#         input_numerical_scaled, columns=numerical_cols_for_scaling, index=input_df.index
#     )
# 
#     # 4. One-hot encode categorical features
#     input_categorical_ohe = pd.get_dummies(input_categorical, drop_first=True)
# 
#     # 5. Concatenate all preprocessed features
#     final_input = pd.concat([input_categorical_ohe, input_numerical_scaled_df], axis=1)
# 
#     # Ensure the order and presence of columns matches training data
#     # This is crucial! Any missing columns (due to a category not present in input_categorical_ohe)
#     # must be added with a value of 0. Extra columns should be dropped.
#     final_input = final_input.reindex(columns=feature_columns, fill_value=0)
# 
#     # Make prediction
#     prediction = model.predict(final_input)
#     prediction_proba = model.predict_proba(final_input)[:, 1]
# 
#     st.subheader("Prediction Results")
#     if prediction[0] == 1:
#         st.success(f"Loan Approval: YES (Probability: {prediction_proba[0]:.2f})")
#         st.balloons()
#     else:
#         st.error(f"Loan Approval: NO (Probability: {prediction_proba[0]:.2f})")
# 
#     st.write("Note: A probability closer to 1 indicates higher likelihood of approval.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# pandas
# scikit-learn
# numpy

# Run the app in the background
!streamlit run finalexamapp.py.py &>/dev/null&

# Get the password (your IP) and print it.
# The "&" runs it in the background while the tunnel starts.
print("Fetching your tunnel password...")
!curl https://loca.lt/mytunnelpassword &

# Start the tunnel. This command will keep the cell running and give you the URL.
!npx localtunnel --port 8501
